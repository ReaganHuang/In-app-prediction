{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering - events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T02:16:51.459401Z",
     "start_time": "2019-02-17T02:16:50.755844Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import IntegerType\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T02:16:55.430118Z",
     "start_time": "2019-02-17T02:16:52.091646Z"
    }
   },
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "ss = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T04:18:49.268997Z",
     "start_time": "2019-02-17T04:17:52.341252Z"
    }
   },
   "outputs": [],
   "source": [
    "users = pd.read_csv('data/user_dict.csv', header=None)\n",
    "user_dict = {row[1][0]:int(row[1][1]) for row in users.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T04:19:27.733542Z",
     "start_time": "2019-02-17T04:19:27.730715Z"
    }
   },
   "outputs": [],
   "source": [
    "name = 'user_id_hash'\n",
    "fn = UserDefinedFunction(lambda x: user_dict[x], IntegerType())\n",
    "df = ss.read.csv('data/events.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert user_id_hash to user_id\n",
    "purchases = df.withColumn('user_id', fn(df.user_id_hash))\\\n",
    "            .drop('user_id_hash', 'app_id', 'session_id')\\\n",
    "            .filter(\"event == 8\")\\\n",
    "            .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases['datetime'] = purchases['event_timestamp']\\\n",
    "                        .apply(lambda x:datetime.fromtimestamp(x/1000))\n",
    "purchases = purchases[(purchases.datetime < '2018-12-01') & (purchases['event_value'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T06:05:45.964602Z",
     "start_time": "2019-02-17T06:05:45.931103Z"
    }
   },
   "outputs": [],
   "source": [
    "f1 = purchases.groupby('user_id')\\\n",
    "                            .size()\\\n",
    "                            .reset_index(name='purchase_count_total')\\\n",
    "                            .set_index('user_id')\n",
    "f2 = purchases[purchases.datetime >= '2018-11-24']\\\n",
    "                            .groupby('user_id')\\\n",
    "                            .size()\\\n",
    "                            .reset_index(name='purchase_count_last_week')\\\n",
    "                            .set_index('user_id')\n",
    "f3 = purchases[purchases.datetime >= '2018-11-17']\\\n",
    "                            .groupby('user_id').size()\\\n",
    "                            .reset_index(name='purchase_count_2_weeks')\\\n",
    "                            .set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T06:05:46.486896Z",
     "start_time": "2019-02-17T06:05:46.450441Z"
    }
   },
   "outputs": [],
   "source": [
    "f4 = purchases.groupby('user_id')['event_value']\\\n",
    "                            .agg('sum')\\\n",
    "                            .reset_index(name='purchase_sum_total')\\\n",
    "                            .set_index('user_id')\n",
    "f5 = purchases[purchases.datetime >= '2018-11-24']\\\n",
    "                            .groupby('user_id')['event_value']\\\n",
    "                            .agg('sum')\\\n",
    "                            .reset_index(name='purchase_sum_last_week')\\\n",
    "                            .set_index('user_id')\n",
    "f6 = purchases[purchases.datetime >= '2018-11-17']\\\n",
    "                            .groupby('user_id')['event_value']\\\n",
    "                            .agg('sum')\\\n",
    "                            .reset_index(name='purchase_sum_2_weeks')\\\n",
    "                            .set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create a dummy df with all user_ids and then join with other features\n",
    "dummy = pd.DataFrame({'user_id': list(user_dict.values()), 'dummy': [0 for _ in range(len(user_dict.values()))]})\n",
    "features_lst = [f1, f2, f3, f4, f5, f6]\n",
    "features = dummy.join(features_lst[:]).drop(axis=1, columns='dummy').fillna(value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T06:32:03.419697Z",
     "start_time": "2019-02-17T06:32:03.306960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32752\n",
      "588748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.055629912967857215"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum(features.purchase_count_total != 0))\n",
    "print(sum(features.purchase_count_total == 0))\n",
    "32752/588748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-17T06:21:30.673497Z",
     "start_time": "2019-02-17T06:21:27.450933Z"
    }
   },
   "outputs": [],
   "source": [
    "features.to_csv(path_or_buf='features_events.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
